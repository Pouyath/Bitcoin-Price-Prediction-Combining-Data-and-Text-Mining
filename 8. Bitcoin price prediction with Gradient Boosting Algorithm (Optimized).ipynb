{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \"0.9\"})\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras import backend as K\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go back Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_back(look_back, df):\n",
    "    #Create previous Day price column \n",
    "    \n",
    "    for i in range(look_back):\n",
    "        name = 'Previous_Day_Price' + str(i)\n",
    "        df[name] = df['Weighted_Price'].shift(+1+i)\n",
    "        df.dropna(how='any', inplace=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweet_n_btc_day.csv')\n",
    "#Drop np.nan\n",
    "df.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop\n",
    "to_drop = ['Unnamed: 0', 'Timestamp', 'A_Lot_Likes', 'Emoticons', 'Positive_Or_Not', 'Count_of_Tweets', \n",
    "           'Count_of_Tweets_Savgol', 'Unnamed: 0_x', 'Open', 'High',\n",
    "       'Low', 'Close', 'Volume_(BTC)', 'Volume_(Currency)','Up_or_Down', 'Count_Of_Possitive_Tweets_Savgol',\n",
    "           'Up_or_Down_Sentiment',\n",
    "          ]\n",
    "\n",
    "df.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look Back "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go back\n",
    "look_back = 5\n",
    "df = go_back(look_back, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.values\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df = scaler.fit_transform(df)\n",
    "\n",
    "dataset = np.delete(df,(3), axis=1)\n",
    "labels = np.delete(df,(0,1,2,4,5,6,7,8,9), axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.4)\n",
    "\n",
    "x_train, x_val, y_train, y_val  = train_test_split(x_train, y_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003144260656474633\n",
      "0.022567625844614147\n",
      "0.027407344132667405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "params = {'max_depth': 9, 'min_weight_fraction_leaf': 0.0004922346204236811, }\n",
    "\n",
    "clf =  GradientBoostingRegressor(**params)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "prediction = clf.predict(x_train)\n",
    "print (math.sqrt(mean_squared_error(prediction,y_train)) )\n",
    "\n",
    "prediction = clf.predict(x_val)\n",
    "print (math.sqrt(mean_squared_error(prediction,y_val)) )\n",
    "\n",
    "prediction = clf.predict(x_test)\n",
    "print ( math.sqrt(mean_squared_error(prediction,y_test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same problem without features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002283790333886877\n",
      "0.035016681312447465\n",
      "0.029951789916949915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('tweet_n_btc_day.csv')\n",
    "#Drop np.nan\n",
    "df.dropna(how='any', inplace=True)\n",
    "\n",
    "df = df[['Weighted_Price']]\n",
    "\n",
    "#Go back\n",
    "look_back = 5\n",
    "df = go_back(look_back, df)\n",
    "\n",
    "df = df.values\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df = scaler.fit_transform(df)\n",
    "\n",
    "dataset = np.delete(df,(0), axis=1)\n",
    "labels = np.delete(df,(1,2,3,4,5), axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.4)\n",
    "\n",
    "x_train, x_val, y_train, y_val  = train_test_split(x_train, y_train, test_size=0.25)\n",
    "\n",
    "params = {'max_depth': 9, 'min_weight_fraction_leaf': 0.0004922346204236811}\n",
    "\n",
    "clf =  GradientBoostingRegressor()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "prediction = clf.predict(x_train)\n",
    "print (math.sqrt(mean_squared_error(prediction,y_train)) )\n",
    "\n",
    "prediction = clf.predict(x_val)\n",
    "print (math.sqrt(mean_squared_error(prediction,y_val)) )\n",
    "\n",
    "prediction = clf.predict(x_test)\n",
    "print ( math.sqrt(mean_squared_error(prediction,y_test)) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
